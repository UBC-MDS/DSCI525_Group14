{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 525 - Web and Cloud Computing\n",
    "## Milestone 1: Tackling big data on your laptop\n",
    "### Group 14\n",
    "Group Members: Sasha Babicki, Cheuk Ho, Sakshi Jain, Zeliha Ural Merpez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Download the data\n",
    "1. Download the data from figshare to your local computer using the figshare API (you can make use of requests library).\n",
    "2. Extract the zip file, again programmatically, similar to how we did it in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: code below is modified from 525 lecture notes\n",
    "https://github.ubc.ca/MDS-2020-21/DSCI_525_web-cloud-comp_students/blob/master/Lectures/Lecture_1_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_id = 14096681  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figshareairline/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_link_only': False,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'id': 26579150,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'size': 58863},\n",
       " {'is_link_only': False,\n",
       "  'name': 'environment.yml',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'id': 26579171,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'size': 192},\n",
       " {'is_link_only': False,\n",
       "  'name': 'README.md',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'id': 26586554,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'size': 5422},\n",
       " {'is_link_only': False,\n",
       "  'name': 'data.zip',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'id': 26766812,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'size': 814041183},\n",
       " {'is_link_only': False,\n",
       "  'name': 'get_data.py',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'id': 26766815,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'size': 4113}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.26 s, sys: 2.87 s, total: 7.13 s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "download_file = \"data.zip\"\n",
    "for file in files:\n",
    "    if file[\"name\"] == download_file:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 1.84 s, total: 14.4 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with zipfile.ZipFile(os.path.join(output_directory, download_file), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Combining data CSVs\n",
    "1. Use one of the following options to combine data CSVs into a single CSV. (Pandas, DASK)\n",
    "2. When combining the csv files make sure to add extra column called \"model\" that identifies the model (tip : you can get this column populated from the file name eg: for file name \"SAM0-UNICON_daily_rainfall_NSW.csv\", the model name is SAM0-UNICON)\n",
    "3. Compare run times and memory usages of these options on different machines within your team, and summarize your observations in your milestone notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_file_path = output_directory + \"combined_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 13663.16 MiB, increment: 0.01 MiB\n",
      "CPU times: user 4min 16s, sys: 6.37 s, total: 4min 22s\n",
      "Wall time: 4min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "files = glob.glob(output_directory + \"*_daily_rainfall_NSW.csv\")\n",
    "df = pd.concat(\n",
    "    (\n",
    "        pd.read_csv(file, index_col=0).assign(\n",
    "            model=re.findall(r\"/(.*)_daily_rainfall\", file)[0]\n",
    "        )\n",
    "        for file in files\n",
    "    )\n",
    ")\n",
    "df.to_csv(combined_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6G\tfigshareairline/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh figshareairline/combined_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 10.3 s, total: 1min 18s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(combined_file_path, index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62467843, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 194 µs, sys: 11 µs, total: 205 µs\n",
      "Wall time: 210 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-27 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>0.554375</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>7.028577</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>0.234757</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>2.097459</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>0.548421</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lat_min   lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "time                                                                        \n",
       "2014-12-27 12:00:00 -30.157068 -29.21466  153.125  154.375       0.554375   \n",
       "2014-12-28 12:00:00 -30.157068 -29.21466  153.125  154.375       7.028577   \n",
       "2014-12-29 12:00:00 -30.157068 -29.21466  153.125  154.375       0.234757   \n",
       "2014-12-30 12:00:00 -30.157068 -29.21466  153.125  154.375       2.097459   \n",
       "2014-12-31 12:00:00 -30.157068 -29.21466  153.125  154.375       0.548421   \n",
       "\n",
       "                       model  \n",
       "time                          \n",
       "2014-12-27 12:00:00  TaiESM1  \n",
       "2014-12-28 12:00:00  TaiESM1  \n",
       "2014-12-29 12:00:00  TaiESM1  \n",
       "2014-12-30 12:00:00  TaiESM1  \n",
       "2014-12-31 12:00:00  TaiESM1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GFDL-ESM4', 'BCC-CSM2-MR', 'AWI-ESM-1-1-LR', 'GFDL-CM4',\n",
       "       'FGOALS-g3', 'CMCC-ESM2', 'NorESM2-LM', 'CanESM5', 'CMCC-CM2-HR4',\n",
       "       'KIOST-ESM', 'BCC-ESM1', 'FGOALS-f3-L', 'NESM3', 'NorESM2-MM',\n",
       "       'INM-CM4-8', 'MRI-ESM2-0', 'SAM0-UNICON', 'MPI-ESM1-2-LR',\n",
       "       'CMCC-CM2-SR5', 'EC-Earth3-Veg-LR', 'MPI-ESM1-2-HR',\n",
       "       'ACCESS-ESM1-5', 'MIROC6', 'INM-CM5-0', 'MPI-ESM-1-2-HAM',\n",
       "       'ACCESS-CM2', 'TaiESM1'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.92 s, sys: 1.25 s, total: 8.17 s\n",
      "Wall time: 8.17 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.924854e+07</td>\n",
       "      <td>6.246784e+07</td>\n",
       "      <td>5.924854e+07</td>\n",
       "      <td>6.246784e+07</td>\n",
       "      <td>5.924854e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.310482e+01</td>\n",
       "      <td>-3.197757e+01</td>\n",
       "      <td>1.469059e+02</td>\n",
       "      <td>1.482150e+02</td>\n",
       "      <td>1.901170e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.963549e+00</td>\n",
       "      <td>1.992067e+00</td>\n",
       "      <td>3.793784e+00</td>\n",
       "      <td>3.809994e+00</td>\n",
       "      <td>5.585735e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.646739e+01</td>\n",
       "      <td>-3.600000e+01</td>\n",
       "      <td>1.406250e+02</td>\n",
       "      <td>1.412500e+02</td>\n",
       "      <td>-3.807373e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.486911e+01</td>\n",
       "      <td>-3.366221e+01</td>\n",
       "      <td>1.434375e+02</td>\n",
       "      <td>1.450000e+02</td>\n",
       "      <td>3.838413e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.300000e+01</td>\n",
       "      <td>-3.204188e+01</td>\n",
       "      <td>1.468750e+02</td>\n",
       "      <td>1.481250e+02</td>\n",
       "      <td>6.154947e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-3.140170e+01</td>\n",
       "      <td>-3.015707e+01</td>\n",
       "      <td>1.501875e+02</td>\n",
       "      <td>1.513125e+02</td>\n",
       "      <td>1.020918e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-2.990000e+01</td>\n",
       "      <td>-2.790606e+01</td>\n",
       "      <td>1.537500e+02</td>\n",
       "      <td>1.556250e+02</td>\n",
       "      <td>4.329395e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat_min       lat_max       lon_min       lon_max  rain (mm/day)\n",
       "count  5.924854e+07  6.246784e+07  5.924854e+07  6.246784e+07   5.924854e+07\n",
       "mean  -3.310482e+01 -3.197757e+01  1.469059e+02  1.482150e+02   1.901170e+00\n",
       "std    1.963549e+00  1.992067e+00  3.793784e+00  3.809994e+00   5.585735e+00\n",
       "min   -3.646739e+01 -3.600000e+01  1.406250e+02  1.412500e+02  -3.807373e-12\n",
       "25%   -3.486911e+01 -3.366221e+01  1.434375e+02  1.450000e+02   3.838413e-06\n",
       "50%   -3.300000e+01 -3.204188e+01  1.468750e+02  1.481250e+02   6.154947e-02\n",
       "75%   -3.140170e+01 -3.015707e+01  1.501875e+02  1.513125e+02   1.020918e+00\n",
       "max   -2.990000e+01 -2.790606e+01  1.537500e+02  1.556250e+02   4.329395e+02"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Runtime Observations: \n",
    "\n",
    "##### Zeliha\n",
    "- Combining files:\n",
    "    - peak memory: 13663.16 MiB, increment: 0.01 MiB\n",
    "    - CPU times: user 4min 16s, sys: 6.37 s, total: 4min 22s\n",
    "    - Wall time: 4min 24s\n",
    "- Reading combined file:\n",
    "    - CPU times: user 45.3 s, sys: 3.61 s, total: 48.9 s\n",
    "    - Wall time: 49 s\n",
    "    \n",
    "##### Sasha\n",
    "- Combining files:\n",
    "    - peak memory: 86.82 MiB, increment: 0.26 MiB\n",
    "    - CPU times: user 6min 14s, sys: 2min 41s, total: 8min 56s\n",
    "    - Wall time: 9min 26s\n",
    "- Reading combined file:\n",
    "    - CPU times: user 1min 8s, sys: 15.3 s, total: 1min 23s\n",
    "    - Wall time: 1min 35s\n",
    "    \n",
    "##### Chuck\n",
    "- Combining files:\n",
    "    - peak memory: 75.36 MiB, increment: 0.71 MiB\n",
    "    - CPU times: user 5min 59s, sys: 15.5 s, total: 6min 15s\n",
    "    - Wall time: 6min 22s\n",
    "- Reading combined file:\n",
    "    - Peak memory: 3355.27 MiB, increment: 0.12 MiB\n",
    "    - CPU times: user 56.9 s, sys: 14.2 s, total: 1min 11s\n",
    "    - Wall time: 1min 14s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Load the combined CSV to memory and perform a simple EDA\n",
    "1. Investigate at least two of the following approaches to reduce memory usage while performing the EDA (e.g., value_counts).\n",
    "    - Changing dtype of your data\n",
    "    - Load just columns what we want\n",
    "    - Loading in chunks\n",
    "    - Dask\n",
    "2. Discuss your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 Changing dtype of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 62467843 entries, 1889-01-01 12:00:00 to 2014-12-31 12:00:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   lat_min        float64\n",
      " 1   lat_max        float64\n",
      " 2   lon_min        float64\n",
      " 3   lon_max        float64\n",
      " 4   rain (mm/day)  float64\n",
      " 5   model          object \n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 3.3+ GB\n"
     ]
    }
   ],
   "source": [
    "# View original dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with numeric columns as float64: 3.50 GB\n",
      "DataFrame with numeric columns as float32: 2.25 GB\n"
     ]
    }
   ],
   "source": [
    "float_cols = [\"lat_min\",\"lat_max\",\"lon_min\",\"lon_max\",\"rain (mm/day)\"]\n",
    "df_32 = df.copy()\n",
    "df_64 = df.copy()\n",
    "\n",
    "df_32[float_cols] = df_32[float_cols].astype('float32', errors='ignore')\n",
    "print(f\"DataFrame with numeric columns as float64: {df_64.memory_usage().sum() / 1e9:.2f} GB\")\n",
    "print(f\"DataFrame with numeric columns as float32: {df_32.memory_usage().sum() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 17142.71 MiB, increment: 0.52 MiB\n",
      "CPU times: user 554 ms, sys: 116 ms, total: 670 ms\n",
      "Wall time: 823 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_64[\"lat_min\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 17618.94 MiB, increment: 476.96 MiB\n",
      "CPU times: user 557 ms, sys: 164 ms, total: 720 ms\n",
      "Wall time: 879 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_32[\"lat_min\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 Dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df_dask = dd.read_csv(combined_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 17142.24 MiB, increment: 0.51 MiB\n",
      "CPU times: user 561 ms, sys: 164 ms, total: 726 ms\n",
      "Wall time: 807 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df[\"lat_min\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 17141.73 MiB, increment: 0.00 MiB\n",
      "CPU times: user 35 ms, sys: 216 ms, total: 251 ms\n",
      "Wall time: 452 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_dask[\"lat_min\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 17141.73 MiB, increment: 0.00 MiB\n",
      "CPU times: user 3.54 s, sys: 188 ms, total: 3.73 s\n",
      "Wall time: 3.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 17141.73 MiB, increment: 0.00 MiB\n",
      "CPU times: user 36.4 ms, sys: 205 ms, total: 242 ms\n",
      "Wall time: 449 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_dask[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Discussion:\n",
    "\n",
    "- Changing the dtype of numeric columns from `float64` to `float32` did reduce the space the dataframe takes in memory by almost half. However, performing `value_counts()` on a column actually used more memory and was slower for `float32` columns than `float64` columns. \n",
    "- Dask seems to use marginally less memory and is slightly faster when performing `value_counts()` on a numeric column. It is significantly faster when operating on a `str` type column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Perform a simple EDA in R\n",
    "1. Pick an approach to transfer the dataframe from python to R.\n",
    "    - Parquet file\n",
    "    - Feather file\n",
    "    - Pandas exchange\n",
    "    - Arrow exchange\n",
    "2. Discuss why you chose this approach over others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install the pyarrow packages: https://arrow.apache.org/docs/python/install.html\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.feather as feather\n",
    "\n",
    "## Install rpy2: https://anaconda.org/conda-forge/rpy2\n",
    "import rpy2.rinterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4395.28 MiB, increment: 2678.63 MiB\n",
      "CPU times: user 5.05 s, sys: 1.83 s, total: 6.88 s\n",
      "Wall time: 6.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "table = pa.Table.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.19 s, sys: 1.25 s, total: 3.43 s\n",
      "Wall time: 3.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Write to feather format \n",
    "feather.write_feather(table, \"figshareairline/example.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1G\tfigshareairline/example.feather\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh figshareairline/example.feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: ‘arrow’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:utils’:\n",
      "\n",
      "    timestamp\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "### her we are showing how much time it took to read a feather file what we wrote in python\n",
    "library(arrow)\n",
    "library(dplyr)\n",
    "\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"figshareairline/example.feather\")\n",
    "print(class(r_table))\n",
    "\n",
    "result <- r_table %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Discussion: \n",
    "- We choose to get table directly from pandas data frame and then save the file as feather. Both constructing table and saving file was quite fast.\n",
    "- Using the feather file format saves a lot of space, the file only takes up ~1.2 GB in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
