{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 525 - Web and Cloud Computing\n",
    "## Milestone 1: Tackling big data on your laptop\n",
    "### Group 14\n",
    "Group Members: Sasha Babicki, Cheuk Ho, Sakshi Jain, Zeliha Ural Merpez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Download the data\n",
    "1. Download the data from figshare to your local computer using the figshare API (you can make use of requests library).\n",
    "2. Extract the zip file, again programmatically, similar to how we did it in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: code below is modified from 525 lecture notes\n",
    "https://github.ubc.ca/MDS-2020-21/DSCI_525_web-cloud-comp_students/blob/master/Lectures/Lecture_1_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext rpy2.ipython  # commenting out until we find a fix\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_id = 14096681 # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figshareairline/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_link_only': False,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'id': 26579150,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'size': 58863},\n",
       " {'is_link_only': False,\n",
       "  'name': 'environment.yml',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'id': 26579171,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'size': 192},\n",
       " {'is_link_only': False,\n",
       "  'name': 'README.md',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'id': 26586554,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'size': 5422},\n",
       " {'is_link_only': False,\n",
       "  'name': 'data.zip',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'id': 26766812,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'size': 814041183},\n",
       " {'is_link_only': False,\n",
       "  'name': 'get_data.py',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'id': 26766815,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'size': 4113}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.85 s, sys: 6.52 s, total: 11.4 s\n",
      "Wall time: 15min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files_to_dl = [\"data.zip\"]  # feel free to add other files here\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.2 s, sys: 11.7 s, total: 28.8 s\n",
      "Wall time: 40 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Combining data CSVs\n",
    "1. Use one of the following options to combine data CSVs into a single CSV. (Pandas, DASK)\n",
    "2. When combining the csv files make sure to add extra column called \"model\" that identifies the model (tip : you can get this column populated from the file name eg: for file name \"SAM0-UNICON_daily_rainfall_NSW.csv\", the model name is SAM0-UNICON)\n",
    "3. Compare run times and memory usages of these options on different machines within your team, and summarize your observations in your milestone notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_file_path = output_directory + \"combined_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 86.82 MiB, increment: 0.26 MiB\n",
      "CPU times: user 6min 14s, sys: 2min 41s, total: 8min 56s\n",
      "Wall time: 9min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "files = glob.glob(output_directory + \"*_daily_rainfall_NSW.csv\")\n",
    "df = pd.concat(\n",
    "    (\n",
    "        pd.read_csv(file, index_col=0).assign(\n",
    "            model=re.findall(r\"/(.*)_daily_rainfall\", file)[0]\n",
    "        )\n",
    "        for file in files\n",
    "    )\n",
    ")\n",
    "df.to_csv(combined_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6G\tfigshareairline/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh figshareairline/combined_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 15.3 s, total: 1min 23s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(combined_file_path, index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62467843, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1889-01-01 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.244226e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-02 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.217326e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-03 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.498125e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-04 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.251282e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-05 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.270161e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lat_min    lat_max   lon_min   lon_max  rain (mm/day)  \\\n",
       "time                                                                           \n",
       "1889-01-01 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.244226e-13   \n",
       "1889-01-02 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.217326e-13   \n",
       "1889-01-03 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.498125e-13   \n",
       "1889-01-04 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.251282e-13   \n",
       "1889-01-05 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.270161e-13   \n",
       "\n",
       "                               model  \n",
       "time                                  \n",
       "1889-01-01 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-02 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-03 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-04 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-05 12:00:00  MPI-ESM-1-2-HAM  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MPI-ESM-1-2-HAM', 'AWI-ESM-1-1-LR', 'NorESM2-LM', 'ACCESS-CM2',\n",
       "       'FGOALS-f3-L', 'CMCC-CM2-HR4', 'MRI-ESM2-0', 'GFDL-CM4',\n",
       "       'BCC-CSM2-MR', 'EC-Earth3-Veg-LR', 'CMCC-ESM2', 'NESM3',\n",
       "       'MPI-ESM1-2-LR', 'ACCESS-ESM1-5', 'FGOALS-g3', 'INM-CM4-8',\n",
       "       'MPI-ESM1-2-HR', 'TaiESM1', 'NorESM2-MM', 'CMCC-CM2-SR5',\n",
       "       'KIOST-ESM', 'INM-CM5-0', 'MIROC6', 'BCC-ESM1', 'GFDL-ESM4',\n",
       "       'CanESM5', 'SAM0-UNICON'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Runtime Observations: \n",
    "\n",
    "##### Zeliha\n",
    "- Combining files:\n",
    "    - peak memory: 130.89 MiB, increment: 0.18 MiB\n",
    "    - Wall time: 14min 21s\n",
    "- Reading combined file:\n",
    "    - Wall time: 5min 27s\n",
    "    \n",
    "##### Sasha\n",
    "- Combining files:\n",
    "    - peak memory: 86.07 MiB, increment: 0.27 MiB\n",
    "    - CPU times: user 6min 14s, sys: 21.9 s, total: 6min 36s\n",
    "    - Wall time: 7min 4s\n",
    "- Reading combined file:\n",
    "    - CPU times: user 59.9 s, sys: 15.4 s, total: 1min 15s\n",
    "    - Wall time: 1min 28s\n",
    "    \n",
    "##### Chuck\n",
    "- Combining files:\n",
    "    - peak memory: 75.36 MiB, increment: 0.71 MiB\n",
    "    - CPU times: user 5min 59s, sys: 15.5 s, total: 6min 15s\n",
    "    - Wall time: 6min 22s\n",
    "- Reading combined file:\n",
    "    - Peak memory: 3355.27 MiB, increment: 0.12 MiB\n",
    "    - CPU times: user 56.9 s, sys: 14.2 s, total: 1min 11s\n",
    "    - Wall time: 1min 14s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Load the combined CSV to memory and perform a simple EDA\n",
    "1. Investigate at least two of the following approaches to reduce memory usage while performing the EDA (e.g., value_counts).\n",
    "    - Changing dtype of your data\n",
    "    - Load just columns what we want\n",
    "    - Loading in chunks\n",
    "    - Dask\n",
    "2. Discuss your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 Changing dtype of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 62467843 entries, 1889-01-01 12:00:00 to 2014-12-31 12:00:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   lat_min        float64\n",
      " 1   lat_max        float64\n",
      " 2   lon_min        float64\n",
      " 3   lon_max        float64\n",
      " 4   rain (mm/day)  float64\n",
      " 5   model          object \n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 3.3+ GB\n"
     ]
    }
   ],
   "source": [
    "# View original dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with numeric columns as float64: 3.50 GB\n",
      "DataFrame with numeric columns as float32: 2.25 GB\n"
     ]
    }
   ],
   "source": [
    "float_cols = [\"lat_min\",\"lat_max\",\"lon_min\",\"lon_max\",\"rain (mm/day)\"]\n",
    "df_32 = df.copy()\n",
    "df_64 = df.copy()\n",
    "\n",
    "df_32[float_cols] = df_32[float_cols].astype('float32', errors='ignore')\n",
    "print(f\"DataFrame with numeric columns as float64: {df_64.memory_usage().sum() / 1e9:.2f} GB\")\n",
    "print(f\"DataFrame with numeric columns as float32: {df_32.memory_usage().sum() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4754.64 MiB, increment: 137.23 MiB\n",
      "CPU times: user 677 ms, sys: 189 ms, total: 865 ms\n",
      "Wall time: 3.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_64[\"lat_min\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 5231.79 MiB, increment: 477.13 MiB\n",
      "CPU times: user 753 ms, sys: 156 ms, total: 909 ms\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_32[\"lat_min\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 Dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df_dask = dd.read_csv(combined_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4634.13 MiB, increment: 67.19 MiB\n",
      "CPU times: user 631 ms, sys: 29.3 ms, total: 660 ms\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df[\"lat_min\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4634.17 MiB, increment: 0.04 MiB\n",
      "CPU times: user 52.3 ms, sys: 20.9 ms, total: 73.2 ms\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_dask[\"lat_min\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4878.47 MiB, increment: 244.29 MiB\n",
      "CPU times: user 4.98 s, sys: 178 ms, total: 5.16 s\n",
      "Wall time: 5.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4878.48 MiB, increment: 0.02 MiB\n",
      "CPU times: user 48.2 ms, sys: 21 ms, total: 69.1 ms\n",
      "Wall time: 1.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_dask[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Discussion:\n",
    "\n",
    "- Changing the dtype of numeric columns from `float64` to `float32` did reduce the space the dataframe takes in memory by almost half. However, performing `value_counts()` on a column actually used more memory and was slower for `float32` columns than `float64` columns. \n",
    "- Dask seems to use marginally less memory and is slightly faster when performing `value_counts()` on a numeric column. It is significantly faster when operating on a `str` type column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Perform a simple EDA in R\n",
    "1. Pick an approach to transfer the dataframe from python to R.\n",
    "    - Parquet file\n",
    "    - Feather file\n",
    "    - Pandas exchange\n",
    "    - Arrow exchange\n",
    "2. Discuss why you chose this approach over others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
