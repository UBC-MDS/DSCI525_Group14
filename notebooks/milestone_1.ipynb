{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 525 - Web and Cloud Computing\n",
    "## Milestone 1: Tackling big data on your laptop\n",
    "### Group 14\n",
    "Group Members: Sasha Babicki, Cheuk Ho, Sakshi Jain, Zeliha Ural Merpez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: code in this milestone is modified from 525 lecture notes\n",
    "https://github.ubc.ca/MDS-2020-21/DSCI_525_web-cloud-comp_students/blob/master/Lectures/Lecture_1_2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Download the data\n",
    "1. Download the data from figshare to your local computer using the figshare API (you can make use of requests library).\n",
    "2. Extract the zip file, again programmatically, similar to how we did it in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"figshareairline/\"\n",
    "combined_file_path = output_directory + \"combined_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_id = 14096681  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_link_only': False,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'id': 26579150,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'size': 58863},\n",
       " {'is_link_only': False,\n",
       "  'name': 'environment.yml',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'id': 26579171,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'size': 192},\n",
       " {'is_link_only': False,\n",
       "  'name': 'README.md',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'id': 26586554,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'size': 5422},\n",
       " {'is_link_only': False,\n",
       "  'name': 'data.zip',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'id': 26766812,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'size': 814041183},\n",
       " {'is_link_only': False,\n",
       "  'name': 'get_data.py',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'id': 26766815,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'size': 4113}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.34 s, sys: 4.73 s, total: 10.1 s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "download_file = \"data.zip\"\n",
    "for file in files:\n",
    "    if file[\"name\"] == download_file:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.9 s, sys: 3.1 s, total: 20 s\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with zipfile.ZipFile(os.path.join(output_directory, download_file), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Combining data CSVs\n",
    "1. Use one of the following options to combine data CSVs into a single CSV. (Pandas, DASK)\n",
    "2. When combining the csv files make sure to add extra column called \"model\" that identifies the model (tip : you can get this column populated from the file name eg: for file name \"SAM0-UNICON_daily_rainfall_NSW.csv\", the model name is SAM0-UNICON)\n",
    "3. Compare run times and memory usages of these options on different machines within your team, and summarize your observations in your milestone notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 157.21 MiB, increment: 0.05 MiB\n",
      "CPU times: user 6min 17s, sys: 15 s, total: 6min 32s\n",
      "Wall time: 6min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "# Combine files and save\n",
    "files = glob.glob(output_directory + \"*_daily_rainfall_NSW.csv\")\n",
    "df = pd.concat(\n",
    "    (\n",
    "        pd.read_csv(file, index_col=0).assign(\n",
    "            model=re.findall(r\"[\\/|\\\\](.*)_daily_rainfall\", file)[0]\n",
    "        )\n",
    "        for file in files\n",
    "    )\n",
    ")\n",
    "df.to_csv(combined_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6G\tfigshareairline/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh figshareairline/combined_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 13.2 s, total: 1min 21s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Read file\n",
    "df = pd.read_csv(combined_file_path, index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62467843, 6)\n",
      "CPU times: user 204 µs, sys: 443 µs, total: 647 µs\n",
      "Wall time: 887 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 3.81 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1889-01-01 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.244226e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-02 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.217326e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-03 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.498125e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-04 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.251282e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-05 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.270161e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-27 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.214660</td>\n",
       "      <td>153.1250</td>\n",
       "      <td>154.3750</td>\n",
       "      <td>6.689683e+00</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.214660</td>\n",
       "      <td>153.1250</td>\n",
       "      <td>154.3750</td>\n",
       "      <td>7.862555e+00</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.214660</td>\n",
       "      <td>153.1250</td>\n",
       "      <td>154.3750</td>\n",
       "      <td>1.000503e+01</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.214660</td>\n",
       "      <td>153.1250</td>\n",
       "      <td>154.3750</td>\n",
       "      <td>8.541592e+00</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.214660</td>\n",
       "      <td>153.1250</td>\n",
       "      <td>154.3750</td>\n",
       "      <td>6.811749e+01</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62467843 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lat_min    lat_max   lon_min   lon_max  rain (mm/day)  \\\n",
       "time                                                                           \n",
       "1889-01-01 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.244226e-13   \n",
       "1889-01-02 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.217326e-13   \n",
       "1889-01-03 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.498125e-13   \n",
       "1889-01-04 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.251282e-13   \n",
       "1889-01-05 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.270161e-13   \n",
       "...                        ...        ...       ...       ...            ...   \n",
       "2014-12-27 12:00:00 -30.157068 -29.214660  153.1250  154.3750   6.689683e+00   \n",
       "2014-12-28 12:00:00 -30.157068 -29.214660  153.1250  154.3750   7.862555e+00   \n",
       "2014-12-29 12:00:00 -30.157068 -29.214660  153.1250  154.3750   1.000503e+01   \n",
       "2014-12-30 12:00:00 -30.157068 -29.214660  153.1250  154.3750   8.541592e+00   \n",
       "2014-12-31 12:00:00 -30.157068 -29.214660  153.1250  154.3750   6.811749e+01   \n",
       "\n",
       "                               model  \n",
       "time                                  \n",
       "1889-01-01 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-02 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-03 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-04 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-05 12:00:00  MPI-ESM-1-2-HAM  \n",
       "...                              ...  \n",
       "2014-12-27 12:00:00      SAM0-UNICON  \n",
       "2014-12-28 12:00:00      SAM0-UNICON  \n",
       "2014-12-29 12:00:00      SAM0-UNICON  \n",
       "2014-12-30 12:00:00      SAM0-UNICON  \n",
       "2014-12-31 12:00:00      SAM0-UNICON  \n",
       "\n",
       "[62467843 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MPI-ESM-1-2-HAM', 'AWI-ESM-1-1-LR', 'NorESM2-LM', 'ACCESS-CM2',\n",
       "       'FGOALS-f3-L', 'CMCC-CM2-HR4', 'MRI-ESM2-0', 'GFDL-CM4',\n",
       "       'BCC-CSM2-MR', 'EC-Earth3-Veg-LR', 'CMCC-ESM2', 'NESM3',\n",
       "       'MPI-ESM1-2-LR', 'ACCESS-ESM1-5', 'FGOALS-g3', 'INM-CM4-8',\n",
       "       'MPI-ESM1-2-HR', 'TaiESM1', 'NorESM2-MM', 'CMCC-CM2-SR5',\n",
       "       'KIOST-ESM', 'INM-CM5-0', 'MIROC6', 'BCC-ESM1', 'GFDL-ESM4',\n",
       "       'CanESM5', 'SAM0-UNICON'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Runtime Observations: \n",
    "\n",
    "##### Summary\n",
    "- The file size of the combined csv is `5.6 GB`. We are using the pandas concat method to combine the data CSVs. \n",
    "- Different run times and memory usages are observed among different machines within the team. The run times range from `4 - 7.5 minutes` It could be a result of different processing power and speed for our laptop. A high memory usage of the system (peak memory) seems to correlate with the lower runtime. \n",
    "- Please find runtime and memory usage observations on different laptops below:\n",
    "\n",
    "\n",
    "##### Zeliha\n",
    "- Combining files:\n",
    "    - peak memory: 13663.16 MiB, increment: 0.01 MiB\n",
    "    - CPU times: user 4min 16s, sys: 6.37 s, total: 4min 22s\n",
    "    - Wall time: 4min 24s\n",
    "- Reading combined file:\n",
    "    - CPU times: user 45.3 s, sys: 3.61 s, total: 48.9 s\n",
    "    - Wall time: 49 s\n",
    "    \n",
    "##### Sasha\n",
    "- Combining files:\n",
    "    - peak memory: 157.21 MiB, increment: 0.05 MiB\n",
    "    - CPU times: user 6min 17s, sys: 15 s, total: 6min 32s\n",
    "    - Wall time: 6min 46s\n",
    "- Reading combined file:\n",
    "    - CPU times: user 1min 8s, sys: 13.2 s, total: 1min 21s\n",
    "    - Wall time: 1min 25s\n",
    "    \n",
    "##### Chuck\n",
    "- Combining files:\n",
    "    - peak memory: 2584.68 MiB, increment: 0.08 MiB\n",
    "    - CPU times: user 5min 32s, sys: 17.7 s, total: 5min 49s\n",
    "    - Wall time: 5min 55s\n",
    "- Reading combined file:\n",
    "    - CPU times: user 56.9 s, sys: 14.2 s, total: 1min 11s\n",
    "    - Wall time: 1min 14s\n",
    "    \n",
    "Note: Sakshi was not able to successfully run this, see issue here for details: https://github.com/UBC-MDS/DSCI525_Group14/issues/17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Load the combined CSV to memory and perform a simple EDA\n",
    "1. Investigate at least two of the following approaches to reduce memory usage while performing the EDA (e.g., value_counts).\n",
    "    - Changing dtype of your data\n",
    "    - Load just columns what we want\n",
    "    - Loading in chunks\n",
    "    - Dask\n",
    "2. Discuss your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 Changing dtype of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 62467843 entries, 1889-01-01 12:00:00 to 2014-12-31 12:00:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   lat_min        float64\n",
      " 1   lat_max        float64\n",
      " 2   lon_min        float64\n",
      " 3   lon_max        float64\n",
      " 4   rain (mm/day)  float64\n",
      " 5   model          object \n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 3.3+ GB\n"
     ]
    }
   ],
   "source": [
    "# View original dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with numeric columns as float64: 3.50 GB\n",
      "DataFrame with numeric columns as float32: 2.25 GB\n"
     ]
    }
   ],
   "source": [
    "float_cols = [\"lat_min\",\"lat_max\",\"lon_min\",\"lon_max\",\"rain (mm/day)\"]\n",
    "df_32 = df.copy()\n",
    "df_64 = df.copy()\n",
    "\n",
    "df_32[float_cols] = df_32[float_cols].astype('float32', errors='ignore')\n",
    "print(f\"DataFrame with numeric columns as float64: {df_64.memory_usage().sum() / 1e9:.2f} GB\")\n",
    "print(f\"DataFrame with numeric columns as float32: {df_32.memory_usage().sum() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4448.21 MiB, increment: 394.99 MiB\n",
      "CPU times: user 709 ms, sys: 325 ms, total: 1.03 s\n",
      "Wall time: 3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_64[\"lat_min\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4924.55 MiB, increment: 477.18 MiB\n",
      "CPU times: user 762 ms, sys: 147 ms, total: 909 ms\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_32[\"lat_min\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 Dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear pandas dataframe to reload in following cell\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 7893.68 MiB, increment: 3446.18 MiB\n",
      "CPU times: user 1min 7s, sys: 12 s, total: 1min 19s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# Pandas - load file\n",
    "df = pd.read_csv(combined_file_path, index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2181.13 MiB, increment: -0.11 MiB\n",
      "CPU times: user 87.7 ms, sys: 123 ms, total: 211 ms\n",
      "Wall time: 3.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# Dask - load file\n",
    "df_dask = dd.read_csv(combined_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2180.78 MiB, increment: 0.06 MiB\n",
      "CPU times: user 769 ms, sys: 346 ms, total: 1.11 s\n",
      "Wall time: 4.61 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-32.041885    3035329\n",
       "-32.984293    3035329\n",
       "-31.099476    3035329\n",
       "-34.869110    3035329\n",
       "-30.000000    1747830\n",
       "               ...   \n",
       "-30.696652     183960\n",
       "-36.277805     183960\n",
       "-33.490981     183960\n",
       "-30.700015     183960\n",
       "-36.281964     183960\n",
       "Name: lat_min, Length: 84, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "# Pandas - value_counts for numeric column with many unique values\n",
    "df[\"lat_min\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2724.75 MiB, increment: 0.01 MiB\n",
      "CPU times: user 1min 27s, sys: 15.2 s, total: 1min 42s\n",
      "Wall time: 51.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-31.099476    3035329\n",
       "-32.984293    3035329\n",
       "-34.869110    3035329\n",
       "-32.041885    3035329\n",
       "-30.000000    1747830\n",
       "               ...   \n",
       "-30.696652     183960\n",
       "-36.277805     183960\n",
       "-36.281964     183960\n",
       "-30.700015     183960\n",
       "-33.487232     183960\n",
       "Name: lat_min, Length: 84, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "# Dask - value_counts for numeric column with many unique values\n",
    "df_dask[\"lat_min\"].value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1097.20 MiB, increment: 0.00 MiB\n",
      "CPU times: user 4.85 s, sys: 118 ms, total: 4.97 s\n",
      "Wall time: 8.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPI-ESM1-2-HR       5154240\n",
       "TaiESM1             3541230\n",
       "CMCC-CM2-SR5        3541230\n",
       "NorESM2-MM          3541230\n",
       "CMCC-ESM2           3541230\n",
       "CMCC-CM2-HR4        3541230\n",
       "SAM0-UNICON         3541153\n",
       "FGOALS-f3-L         3219300\n",
       "GFDL-ESM4           3219300\n",
       "GFDL-CM4            3219300\n",
       "EC-Earth3-Veg-LR    3037320\n",
       "MRI-ESM2-0          3037320\n",
       "BCC-CSM2-MR         3035340\n",
       "MIROC6              2070900\n",
       "ACCESS-CM2          1932840\n",
       "ACCESS-ESM1-5       1610700\n",
       "INM-CM5-0           1609650\n",
       "INM-CM4-8           1609650\n",
       "FGOALS-g3           1287720\n",
       "KIOST-ESM           1287720\n",
       "MPI-ESM1-2-LR        966420\n",
       "MPI-ESM-1-2-HAM      966420\n",
       "NESM3                966420\n",
       "AWI-ESM-1-1-LR       966420\n",
       "NorESM2-LM           919800\n",
       "CanESM5              551880\n",
       "BCC-ESM1             551880\n",
       "Name: model, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "# Pandas - value_counts for str column with few unique values\n",
    "df[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1216.67 MiB, increment: 0.01 MiB\n",
      "CPU times: user 1min 26s, sys: 13.9 s, total: 1min 40s\n",
      "Wall time: 50.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPI-ESM1-2-HR       5154240\n",
       "TaiESM1             3541230\n",
       "NorESM2-MM          3541230\n",
       "CMCC-CM2-HR4        3541230\n",
       "CMCC-CM2-SR5        3541230\n",
       "CMCC-ESM2           3541230\n",
       "SAM0-UNICON         3541153\n",
       "FGOALS-f3-L         3219300\n",
       "GFDL-CM4            3219300\n",
       "GFDL-ESM4           3219300\n",
       "EC-Earth3-Veg-LR    3037320\n",
       "MRI-ESM2-0          3037320\n",
       "BCC-CSM2-MR         3035340\n",
       "MIROC6              2070900\n",
       "ACCESS-CM2          1932840\n",
       "ACCESS-ESM1-5       1610700\n",
       "INM-CM5-0           1609650\n",
       "INM-CM4-8           1609650\n",
       "KIOST-ESM           1287720\n",
       "FGOALS-g3           1287720\n",
       "MPI-ESM1-2-LR        966420\n",
       "NESM3                966420\n",
       "AWI-ESM-1-1-LR       966420\n",
       "MPI-ESM-1-2-HAM      966420\n",
       "NorESM2-LM           919800\n",
       "BCC-ESM1             551880\n",
       "CanESM5              551880\n",
       "Name: model, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "# Dask - value_counts for str column with few unique values\n",
    "df_dask[\"model\"].value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1097.90 MiB, increment: 0.02 MiB\n",
      "CPU times: user 13.1 s, sys: 8.31 s, total: 21.4 s\n",
      "Wall time: 26.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.924854e+07</td>\n",
       "      <td>6.246784e+07</td>\n",
       "      <td>5.924854e+07</td>\n",
       "      <td>6.246784e+07</td>\n",
       "      <td>5.924854e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.310482e+01</td>\n",
       "      <td>-3.197757e+01</td>\n",
       "      <td>1.469059e+02</td>\n",
       "      <td>1.482150e+02</td>\n",
       "      <td>1.901170e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.963549e+00</td>\n",
       "      <td>1.992067e+00</td>\n",
       "      <td>3.793784e+00</td>\n",
       "      <td>3.809994e+00</td>\n",
       "      <td>5.585735e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.646739e+01</td>\n",
       "      <td>-3.600000e+01</td>\n",
       "      <td>1.406250e+02</td>\n",
       "      <td>1.412500e+02</td>\n",
       "      <td>-3.807373e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.486911e+01</td>\n",
       "      <td>-3.366221e+01</td>\n",
       "      <td>1.434375e+02</td>\n",
       "      <td>1.450000e+02</td>\n",
       "      <td>3.838413e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.300000e+01</td>\n",
       "      <td>-3.204188e+01</td>\n",
       "      <td>1.468750e+02</td>\n",
       "      <td>1.481250e+02</td>\n",
       "      <td>6.154947e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-3.140170e+01</td>\n",
       "      <td>-3.015707e+01</td>\n",
       "      <td>1.501875e+02</td>\n",
       "      <td>1.513125e+02</td>\n",
       "      <td>1.020918e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-2.990000e+01</td>\n",
       "      <td>-2.790606e+01</td>\n",
       "      <td>1.537500e+02</td>\n",
       "      <td>1.556250e+02</td>\n",
       "      <td>4.329395e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat_min       lat_max       lon_min       lon_max  rain (mm/day)\n",
       "count  5.924854e+07  6.246784e+07  5.924854e+07  6.246784e+07   5.924854e+07\n",
       "mean  -3.310482e+01 -3.197757e+01  1.469059e+02  1.482150e+02   1.901170e+00\n",
       "std    1.963549e+00  1.992067e+00  3.793784e+00  3.809994e+00   5.585735e+00\n",
       "min   -3.646739e+01 -3.600000e+01  1.406250e+02  1.412500e+02  -3.807373e-12\n",
       "25%   -3.486911e+01 -3.366221e+01  1.434375e+02  1.450000e+02   3.838413e-06\n",
       "50%   -3.300000e+01 -3.204188e+01  1.468750e+02  1.481250e+02   6.154947e-02\n",
       "75%   -3.140170e+01 -3.015707e+01  1.501875e+02  1.513125e+02   1.020918e+00\n",
       "max   -2.990000e+01 -2.790606e+01  1.537500e+02  1.556250e+02   4.329395e+02"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "# Pandas - summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3107.04 MiB, increment: 0.14 MiB\n",
      "CPU times: user 1min 43s, sys: 20.4 s, total: 2min 3s\n",
      "Wall time: 56.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.924854e+07</td>\n",
       "      <td>6.246784e+07</td>\n",
       "      <td>5.924854e+07</td>\n",
       "      <td>6.246784e+07</td>\n",
       "      <td>5.924854e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.310482e+01</td>\n",
       "      <td>-3.197757e+01</td>\n",
       "      <td>1.469059e+02</td>\n",
       "      <td>1.482150e+02</td>\n",
       "      <td>1.901170e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.963549e+00</td>\n",
       "      <td>1.992067e+00</td>\n",
       "      <td>3.793784e+00</td>\n",
       "      <td>3.809994e+00</td>\n",
       "      <td>5.585735e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.646739e+01</td>\n",
       "      <td>-3.600000e+01</td>\n",
       "      <td>1.406250e+02</td>\n",
       "      <td>1.412500e+02</td>\n",
       "      <td>-3.807373e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.437500e+01</td>\n",
       "      <td>-3.310000e+01</td>\n",
       "      <td>1.455469e+02</td>\n",
       "      <td>1.468125e+02</td>\n",
       "      <td>5.060700e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.290000e+01</td>\n",
       "      <td>-3.170937e+01</td>\n",
       "      <td>1.481250e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>2.565542e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-3.109948e+01</td>\n",
       "      <td>-3.000000e+01</td>\n",
       "      <td>1.518750e+02</td>\n",
       "      <td>1.531250e+02</td>\n",
       "      <td>2.824743e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-2.990000e+01</td>\n",
       "      <td>-2.790606e+01</td>\n",
       "      <td>1.537500e+02</td>\n",
       "      <td>1.556250e+02</td>\n",
       "      <td>4.329395e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat_min       lat_max       lon_min       lon_max  rain (mm/day)\n",
       "count  5.924854e+07  6.246784e+07  5.924854e+07  6.246784e+07   5.924854e+07\n",
       "mean  -3.310482e+01 -3.197757e+01  1.469059e+02  1.482150e+02   1.901170e+00\n",
       "std    1.963549e+00  1.992067e+00  3.793784e+00  3.809994e+00   5.585735e+00\n",
       "min   -3.646739e+01 -3.600000e+01  1.406250e+02  1.412500e+02  -3.807373e-12\n",
       "25%   -3.437500e+01 -3.310000e+01  1.455469e+02  1.468125e+02   5.060700e-03\n",
       "50%   -3.290000e+01 -3.170937e+01  1.481250e+02  1.500000e+02   2.565542e-01\n",
       "75%   -3.109948e+01 -3.000000e+01  1.518750e+02  1.531250e+02   2.824743e+00\n",
       "max   -2.990000e+01 -2.790606e+01  1.537500e+02  1.556250e+02   4.329395e+02"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "# Dask - summary statistics\n",
    "df_dask.describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 6937.61 MiB, increment: 4413.84 MiB\n",
      "CPU times: user 18 s, sys: 6.14 s, total: 24.1 s\n",
      "Wall time: 26.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# Pandas - multiple operations\n",
    "df[\"lat_min\"].value_counts()\n",
    "df[\"model\"].value_counts()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3818.21 MiB, increment: 693.53 MiB\n",
      "CPU times: user 1min 48s, sys: 20.3 s, total: 2min 8s\n",
      "Wall time: 59.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# Dask - multiple operations\n",
    "dd.compute(\n",
    "    df_dask[\"lat_min\"].value_counts(),\n",
    "    df_dask[\"model\"].value_counts(),\n",
    "    df_dask.describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Discussion:\n",
    "\n",
    "- Changing the dtype of numeric columns from `float64` to `float32` did reduce the space the dataframe takes in memory by almost half. However, performing `value_counts()` on a column actually used more memory and was slower for `float32` columns than `float64` columns. This may be due to type conversions happening under the hood. \n",
    "- Reading data from csv into a local variable is much faster and takes less memory when using `dask` rather than `pandas`. This makes sense because `dask` loads a representation of the structure of the dataframe rather than the data itself, whereas `pandas` loads all the data into memory. `dask` seems to use a similar amount of memory to `pandas` when performing `value_counts()` on columns, but is much slower than `pandas` when computing `value_counts()` for a single column. We expect this is because the data needs to be loaded into memory when the task is being performed, whereas with `pandas` this step is already complete. When performing multiple operations with `dask` there is far less memory usage, however the speed of the operation is almost double that of `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Perform a simple EDA in R\n",
    "1. Pick an approach to transfer the dataframe from python to R.\n",
    "    - Parquet file\n",
    "    - Feather file\n",
    "    - Pandas exchange\n",
    "    - Arrow exchange\n",
    "2. Discuss why you chose this approach over others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install the pyarrow packages: https://arrow.apache.org/docs/python/install.html\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.feather as feather\n",
    "\n",
    "## Install rpy2: https://anaconda.org/conda-forge/rpy2\n",
    "import rpy2.rinterface\n",
    "\n",
    "import rpy2_arrow.pyarrow_rarrow as pyra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(arrow)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1 Convert Table with Pandas and Save File in Feather Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4085.97 MiB, increment: 1439.46 MiB\n",
      "CPU times: user 4.67 s, sys: 940 ms, total: 5.62 s\n",
      "Wall time: 5.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "table = pa.Table.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4086.95 MiB, increment: 0.23 MiB\n",
      "CPU times: user 2.51 s, sys: 1.88 s, total: 4.39 s\n",
      "Wall time: 7.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "# Write to feather format \n",
    "feather.write_feather(table, \"figshareairline/combined.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1G\tfigshareairline/combined.feather\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh figshareairline/combined.feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "\u001b[90m# A tibble: 27 x 2\u001b[39m\n",
      "   model                  n\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m ACCESS-CM2       1\u001b[4m9\u001b[24m\u001b[4m3\u001b[24m\u001b[4m2\u001b[24m840\n",
      "\u001b[90m 2\u001b[39m ACCESS-ESM1-5    1\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m\u001b[4m0\u001b[24m700\n",
      "\u001b[90m 3\u001b[39m AWI-ESM-1-1-LR    \u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m6\u001b[24m420\n",
      "\u001b[90m 4\u001b[39m BCC-CSM2-MR      3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m5\u001b[24m340\n",
      "\u001b[90m 5\u001b[39m BCC-ESM1          \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 6\u001b[39m CanESM5           \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 7\u001b[39m CMCC-CM2-HR4     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 8\u001b[39m CMCC-CM2-SR5     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 9\u001b[39m CMCC-ESM2        3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m10\u001b[39m EC-Earth3-Veg-LR 3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m7\u001b[24m320\n",
      "\u001b[90m# … with 17 more rows\u001b[39m\n",
      "Time difference of 33.11376 secs\n",
      "CPU times: user 11.1 s, sys: 13.6 s, total: 24.7 s\n",
      "Wall time: 33.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"figshareairline/combined.feather\")\n",
    "print(class(r_table))\n",
    "\n",
    "result <- r_table %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2 Convert Table with Arrow and Save File in Feather Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 5460.56 MiB, increment: 0.17 MiB\n",
      "CPU times: user 19.9 s, sys: 11.1 s, total: 31 s\n",
      "Wall time: 33.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "dataset_arrow = ds.dataset(combined_file_path, format=\"csv\")\n",
    "\n",
    "# arrow table format\n",
    "table_arrow = dataset_arrow.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "time: timestamp[s]\n",
       "lat_min: double\n",
       "lat_max: double\n",
       "lon_min: double\n",
       "lon_max: double\n",
       "rain (mm/day): double\n",
       "model: string"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4685.31 MiB, increment: -156.72 MiB\n",
      "CPU times: user 4.54 s, sys: 9.27 s, total: 13.8 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "# experiment in writing in feather format \n",
    "feather.write_feather(table_arrow, 'figshareairline/arrow_combined.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0G\tfigshareairline/arrow_combined.feather\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh figshareairline/arrow_combined.feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "\u001b[90m# A tibble: 27 x 2\u001b[39m\n",
      "   model                  n\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m ACCESS-CM2       1\u001b[4m9\u001b[24m\u001b[4m3\u001b[24m\u001b[4m2\u001b[24m840\n",
      "\u001b[90m 2\u001b[39m ACCESS-ESM1-5    1\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m\u001b[4m0\u001b[24m700\n",
      "\u001b[90m 3\u001b[39m AWI-ESM-1-1-LR    \u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m6\u001b[24m420\n",
      "\u001b[90m 4\u001b[39m BCC-CSM2-MR      3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m5\u001b[24m340\n",
      "\u001b[90m 5\u001b[39m BCC-ESM1          \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 6\u001b[39m CanESM5           \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 7\u001b[39m CMCC-CM2-HR4     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 8\u001b[39m CMCC-CM2-SR5     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 9\u001b[39m CMCC-ESM2        3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m10\u001b[39m EC-Earth3-Veg-LR 3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m7\u001b[24m320\n",
      "\u001b[90m# … with 17 more rows\u001b[39m\n",
      "Time difference of 1.064979 mins\n",
      "CPU times: user 13.5 s, sys: 24.6 s, total: 38.1 s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"figshareairline/arrow_combined.feather\")\n",
    "print(class(r_table))\n",
    "\n",
    "result <- r_table %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3 Convert Table with Arrow and Directly Loaded into R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 5443.09 MiB, increment: 0.25 MiB\n",
      "5695\n",
      "rarrow.ChunkedArray: 0.0340421199798584\n",
      "5695\n",
      "rarrow.ChunkedArray: 0.022715091705322266\n",
      "5695\n",
      "rarrow.ChunkedArray: 0.0239717960357666\n",
      "5695\n",
      "rarrow.ChunkedArray: 0.030026912689208984\n",
      "5695\n",
      "rarrow.ChunkedArray: 0.031365156173706055\n",
      "5695\n",
      "rarrow.ChunkedArray: 0.02218317985534668\n",
      "5695\n",
      "rarrow.ChunkedArray: 0.024814128875732422\n",
      "CPU times: user 25.9 s, sys: 3.54 s, total: 29.5 s\n",
      "Wall time: 34.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "r_table = pyra.converter.py2rpy(table_arrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "\u001b[90m# A tibble: 27 x 2\u001b[39m\n",
      "   model                  n\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m ACCESS-CM2       1\u001b[4m9\u001b[24m\u001b[4m3\u001b[24m\u001b[4m2\u001b[24m840\n",
      "\u001b[90m 2\u001b[39m ACCESS-ESM1-5    1\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m\u001b[4m0\u001b[24m700\n",
      "\u001b[90m 3\u001b[39m AWI-ESM-1-1-LR    \u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m6\u001b[24m420\n",
      "\u001b[90m 4\u001b[39m BCC-CSM2-MR      3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m5\u001b[24m340\n",
      "\u001b[90m 5\u001b[39m BCC-ESM1          \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 6\u001b[39m CanESM5           \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 7\u001b[39m CMCC-CM2-HR4     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 8\u001b[39m CMCC-CM2-SR5     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 9\u001b[39m CMCC-ESM2        3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m10\u001b[39m EC-Earth3-Veg-LR 3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m7\u001b[24m320\n",
      "\u001b[90m# … with 17 more rows\u001b[39m\n",
      "Time difference of 9.672174 secs\n"
     ]
    }
   ],
   "source": [
    "%%R -i r_table\n",
    "\n",
    "start_time <- Sys.time()\n",
    "print(class(r_table %>% collect()))\n",
    "result2 <- r_table %>% collect() %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(result2)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Discussion: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Observation Summary - Chuck's Laptop**\n",
    "\n",
    "|                                                                | Peak Memory(MiB) | Increment memory (MiB) | Wall Time (s) | File Size |\n",
    "| -------------------------------------------------------------- | ---------------- | ---------------------- | ------------- | --------- |\n",
    "| Convert to Table - Pandas                                      | 5406             | 1019.34                | 3.86          | NA        |\n",
    "| Convert to Table - Arrow                                       | 9439             | \\-6.78                 | 42.1          | NA        |\n",
    "|                                                                |                  |                        |               |           |\n",
    "| Write File to Feather - Pandas                                 | 5446             | \\-32.73                | 24.6          | 1.1G      |\n",
    "| Write File to Feather - Arrow                                  | 4227             | \\-11.76                | 25.2          | 1.0G      |\n",
    "|                                                                |                  |                        |               |           |\n",
    "| Direct Convert python table to R with Arrow (converter.py2rpy) | 8801             | \\-242.04               | 70            | NA        |\n",
    "|                                                                |                  |                        |               |           |\n",
    "| EDA - Feather + Pandas                                         | NA               | NA                     | 18.1          | NA        |\n",
    "| EDA - Feather + Arrows                                         | NA               | NA                     | 26.2          | NA        |\n",
    "| EDA - Directly Loading with converter.py2rpy                   | NA               | NA                     | 8             | NA        |\n",
    "|                                                                |                  |                        |               |           |\n",
    "|                                                                |                  |                        |               |           |\n",
    "| **Overall Run Time -  Feather + Pandas**                           | NA               | NA                     | **46.6**         | NA        |\n",
    "| **Overall Run Time -  Feather + Arrows**                           | NA               | NA                     | **93.5**          | NA        |\n",
    "| **Overall Run Time -   Direct Convert with converter.py2rpy**      | NA               | NA                     | **120.1**         | NA        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We would want to have faster runtime. We chose feather over parquet because the operations of parquet would be slower as it compress the data to saving storage that may hinder the speed. We would probably use parquet if we want to consider more long term storage. In this case, the file size using feather would be sufficiently small. \n",
    "- We tried getting a table from Pandas and Arrow. We choose to get a table directly from the pandas data frame and then save the file as feather. It runs quite fast from `constructing table, saving file, reading the file into R and performing EDA (i.e. value_counts())`.\n",
    "- As we expected, using the feather file format already saves a lot of space, the file only takes up `~1.1 GB` in memory compared to 5.6 GB with CSV. It's sufficiently small for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
